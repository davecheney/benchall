# These configs rely on the fact that previous branches will overwrite any
# environment variables that they need. Currently, 1.0 and 1.1 jobs use the
# old e2e.sh script on their branches. To turn up new upgrade jobs from these
# releases, you will need to fiddle with e2e.sh on their branches. For all
# branches after those, you will simply need to add a new entry in one of the
# projects below.

- job-template:
    name: 'kubernetes-upgrade-{provider}-{version-old}-{version-new}'
    disabled: false
    description: 'Upgrade multijob from {version-old} to {version-new}. Test owner: ihmccreery.'
    project-type: multijob
    triggers:
        - timed: '@hourly'
    builders:
        # TODO(ihmccreery) In theory, we could get ourselves into trouble by
        # editing these things in the middle of a run.  Jenkins Job Builder
        # would delete jobs, and they'd leave resources lying around.  We
        # should either (1) make this not a multi-job, or (2) add a script here
        # to update these jobs only at the beginning of a multijob run.
        #
        # This pain would also pretty much disappear with #18119, too.
        - multijob:
            name: Deploy
            condition: SUCCESSFUL
            projects:
                - name: 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-step1-deploy'
        - multijob:
            name: Kubectl Test New
            condition: COMPLETED
            projects:
                - name: 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-step2-kubectl-e2e-new'
        - multijob:
            name: Upgrade Master
            condition: COMPLETED
            projects:
                - name: 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-step3-upgrade-master'
        - multijob:
            name: Test Old
            condition: COMPLETED
            projects:
                - name: 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-step4-e2e-old'
        - multijob:
            name: Upgrade Cluster
            condition: COMPLETED
            projects:
                - name: 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-step5-upgrade-cluster'
        - multijob:
            name: Test Old
            condition: COMPLETED
            projects:
                - name: 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-step6-e2e-old'
        - multijob:
            name: Test New
            condition: COMPLETED
            projects:
                - name: 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-step7-e2e-new'

- job-template:
    name: 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-step1-deploy'
    description: 'Deploy a cluster at {version-old} to be tested and upgraded to {version-new}. Test owner: ihmccreery.'
    logrotate:
        daysToKeep: 7
    builders:
        - shell: |
            # per-provider variables
            {provider-env}
            # per-upgrade-flow variables, such as project name
            {project-env}
            # per-step variables, such as whether to run tests
            {job-env}
            {post-env}
            timeout -k {kill-timeout}m 60m {runner} && rc=$? || rc=$?
            {report-rc}
    properties:
        - mail-watcher
    publishers:
        - claim-build
        # No junit-publisher, since we're not running any tests
        - gcs-uploader
        - log-parser
        - email-ext:
            recipients: 'ihmccreery@google.com'
    wrappers:
        - ansicolor:
            colormap: xterm
        - timeout:
            timeout: '{jenkins-timeout}'
            fail: true
        - timestamps
        - workspace-cleanup

- job-template:
    name: 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-{step}'
    description: '{description} Test owner: ihmccreery.'
    # Use the same workspace as step1
    workspace: /var/lib/jenkins/jobs/kubernetes-upgrade-{provider}-{version-old}-{version-new}-step1-deploy/workspace/
    logrotate:
        daysToKeep: 7
    builders:
        - shell: |
            # per-provider variables
            {provider-env}
            # per-upgrade-flow variables, such as project name
            {project-env}
            # per-step variables, such as whether to run tests
            {job-env}
            {post-env}
            timeout -k {kill-timeout}m 300m {runner} && rc=$? || rc=$?
            {report-rc}
    properties:
        - mail-watcher
    publishers:
        - claim-build
        - junit-publisher
        - gcs-uploader
        - log-parser
        - email-ext:
            recipients: 'ihmccreery@google.com'
    wrappers:
        - ansicolor:
            colormap: xterm
        - timeout:
            timeout: '{jenkins-timeout}'
            fail: true
        - timestamps
        # Don't clean the workspace; we want to keep configs intact across steps in the multijob

- job-group:
    name: '{provider}-{version-old}-{version-new}-upgrades'
    jobs:
        - 'kubernetes-upgrade-{provider}-{version-old}-{version-new}'
        - 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-step1-deploy':
            runner: '{runner-old}'
            job-env: |
                export E2E_TEST="false"
                export E2E_DOWN="false"
        - 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-{step}':
            step: 'step2-kubectl-e2e-new'
            runner: '{runner-new}'
            description: 'Run {version-new} kubectl tests against the cluster running {version-old}.'
            job-env: |
                export E2E_OPT="--check_version_skew=false"
                export E2E_UP="false"
                export E2E_DOWN="false"
                export GINKGO_TEST_ARGS="--ginkgo.focus=Kubectl"
        - 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-{step}':
            step: 'step3-upgrade-master'
            runner: '{runner-new}'
            description: 'Upgrade the master from {version-old} to {version-new}.'
            job-env: |
                export E2E_OPT="--check_version_skew=false"
                export E2E_UP="false"
                export E2E_DOWN="false"
                export GINKGO_TEST_ARGS="--ginkgo.focus=\[Feature:MasterUpgrade\]"
        - 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-{step}':
            step: 'step4-e2e-old'
            runner: '{runner-old}'
            description: 'Run {version-old} e2e tests against the cluster with master at {version-new} and nodes still at {version-old}.'
            job-env: |
                export E2E_OPT="--check_version_skew=false"
                export E2E_UP="false"
                export E2E_DOWN="false"
        - 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-{step}':
            step: 'step5-upgrade-cluster'
            runner: '{runner-new}'
            description: 'Upgrade the nodes from {version-old} to {version-new}.'
            job-env: |
                export E2E_OPT="--check_version_skew=false"
                export E2E_UP="false"
                export E2E_DOWN="false"
                export GINKGO_TEST_ARGS="--ginkgo.focus=\[Feature:NodeUpgrade\]"
        - 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-{step}':
            step: 'step6-e2e-old'
            runner: '{runner-old}'
            description: 'Run {version-old} e2e tests against the cluster with master and nodes at {version-new}.'
            job-env: |
                export E2E_OPT="--check_version_skew=false"
                export E2E_UP="false"
                export E2E_DOWN="false"
        - 'kubernetes-upgrade-{provider}-{version-old}-{version-new}-{step}':
            step: 'step7-e2e-new'
            runner: '{runner-new}'
            description: 'Run {version-new} e2e tests against the cluster with master and nodes at {version-new}.'
            job-env: |
                # TODO(15011): these really shouldn't be (very) version skewed, but
                # because we have to get ci/latest again, it could get slightly out of
                # whack.
                export E2E_OPT="--check_version_skew=false"
                export E2E_UP="false"

- project:
    name: 'upgrade-gke'
    provider-env: |
        {gke-provider-env}
        export JENKINS_TOLERATE_DIRTY_WORKSPACE="y"
        export FAIL_ON_GCP_RESOURCE_LEAK="false"
    jobs:
        - '{provider}-{version-old}-{version-new}-upgrades':
            provider: 'gke'
            version-old: '1.1'
            version-new: 'master'
            runner-old: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/release-1.1/hack/jenkins/e2e.sh" | bash -
            runner-new: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/master/hack/jenkins/e2e-runner.sh" | bash -
            project-env: |
                export E2E_NAME="upgrade-gke-1-1-master"
                export PROJECT="kubernetes-jenkins-gke-upgrade"
        - '{provider}-{version-old}-{version-new}-upgrades':
            provider: 'gke'
            version-old: '1.0'
            version-new: 'master'
            runner-old: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/release-1.0/hack/jenkins/e2e.sh" | bash -
            runner-new: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/master/hack/jenkins/e2e-runner.sh" | bash -
            project-env: |
                export E2E_NAME="upgrade-gke-1-0-master"
                export PROJECT="kubernetes-jenkins-gke-upgrade"
        - '{provider}-{version-old}-{version-new}-upgrades':
            provider: 'gke'
            version-old: '1.0'
            version-new: 'current-release'
            runner-old: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/release-1.0/hack/jenkins/e2e.sh" | bash -
            runner-new: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/release-1.1/hack/jenkins/e2e.sh" | bash -
            project-env: ''
        - '{provider}-{version-old}-{version-new}-upgrades':
            provider: 'gke'
            version-old: 'stable'
            version-new: 'current-release'
            runner-old: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/release-1.1/hack/jenkins/e2e.sh" | bash -
            runner-new: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/release-1.1/hack/jenkins/e2e.sh" | bash -
            project-env: ''

- project:
    name: 'upgrade-gce'
    provider-env: |
        {gce-provider-env}
        export NUM_NODES=5
        export JENKINS_TOLERATE_DIRTY_WORKSPACE="y"
        export FAIL_ON_GCP_RESOURCE_LEAK="false"
    jobs:
        - '{provider}-{version-old}-{version-new}-upgrades':
            provider: 'gce'
            version-old: '1.1'
            version-new: 'master'
            runner-old: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/release-1.1/hack/jenkins/e2e.sh" | bash -
            runner-new: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/master/hack/jenkins/e2e-runner.sh" | bash -
            project-env: |
                export E2E_NAME="upgrade-gce-1-1-master"
                export PROJECT="kubernetes-jenkins-gce-upgrade"
        - '{provider}-{version-old}-{version-new}-upgrades':
            provider: 'gce'
            version-old: 'stable'
            version-new: 'current-release'
            runner-old: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/release-1.1/hack/jenkins/e2e.sh" | bash -
            runner-new: curl -fsS --retry 3  "https://raw.githubusercontent.com/kubernetes/kubernetes/release-1.1/hack/jenkins/e2e.sh" | bash -
            project-env: ''
